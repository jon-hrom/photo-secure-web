'''
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –±—Ä–∞–∫ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤ –ø–∞–ø–∫—É tech_rejects
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π OpenCV –∞–ª–≥–æ—Ä–∏—Ç–º —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
Args: event —Å folder_id –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
Returns: –°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ
'''

import json
import os
import io
from typing import Dict, Any, List, Tuple
import psycopg2
from psycopg2.extras import RealDictCursor
import boto3
from botocore.client import Config
import cv2
import numpy as np
from PIL import Image


def detect_closed_eyes(img: np.ndarray) -> bool:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –∑–∞–∫—Ä—ã—Ç—ã—Ö –≥–ª–∞–∑ - –°–¢–†–û–ñ–ï –∫ –ª–æ–∂–Ω—ã–º —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è–º
    –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–∏—â—É—Ä –ø—Ä–∏ —É–ª—ã–±–∫–µ –ù–ï –î–û–õ–ñ–ï–ù —Å—á–∏—Ç–∞—Ç—å—Å—è –∑–∞–∫—Ä—ã—Ç—ã–º–∏ –≥–ª–∞–∑–∞–º–∏!
    
    –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏:
    - –ü–æ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥ EAR (–∑—Ä–∞—á–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –±–æ–ª–µ–µ –∑–∞–º–µ—Ç–Ω—ã)
    - –£–≤–µ–ª–∏—á–µ–Ω –ø–æ—Ä–æ–≥ —è—Ä–∫–æ—Å—Ç–∏ (–±–µ–ª–∫–∏ –≥–ª–∞–∑ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —è—Ä—á–µ)
    - –¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è "–≥–ª–∞–∑–∞ –∑–∞–∫—Ä—ã—Ç—ã"
    - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ª—É—á—à–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞–∫, —á–µ–º –æ—Ç–±—Ä–∞–∫–æ–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ñ–æ—Ç–æ
    
    Returns: True –µ—Å–ª–∏ –û–î–ù–û–ó–ù–ê–ß–ù–û –∑–∞–∫—Ä—ã—Ç—ã –≥–ª–∞–∑–∞ –ë–ï–ó —É–ª—ã–±–∫–∏, False –≤ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö
    """
    try:
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
        smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')
        
        # –ú–µ–¥–∏–∞–Ω–Ω—ã–π –±–ª—é—Ä –¥–ª—è —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è
        img_filtered = cv2.medianBlur(img, 5)
        gray = cv2.cvtColor(img_filtered, cv2.COLOR_BGR2GRAY)
        
        # CLAHE –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)
        
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
        
        if len(faces) == 0:
            print('[TECH_SORT] No faces detected ‚Üí ACCEPT (no rejection without faces)')
            return False
        
        faces_with_definitely_closed_eyes = 0
        faces_ok = 0
        
        for (x, y, w, h) in faces:
            print(f'[TECH_SORT] Analyzing face at ({x},{y}) size {w}x{h}')
            
            face_roi = gray[y:y+h, x:x+w]
            
            if face_roi.size == 0:
                continue
            
            # Upscale small faces
            if w < 80 or h < 80:
                scale_factor = 120 / min(w, h)
                new_w = int(w * scale_factor)
                new_h = int(h * scale_factor)
                face_roi = cv2.resize(face_roi, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
                print(f'[TECH_SORT] Face upscaled from {w}x{h} to {new_w}x{new_h}')
                w, h = new_w, new_h
            
            # –®–ê–ì 1: –î–µ—Ç–µ–∫—Ü–∏—è —É–ª—ã–±–∫–∏ (–°–¢–†–û–ñ–ï - —Ç—Ä–µ–±—É–µ–º –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
            mouth_region_y = int(h * 0.5)
            mouth_region = face_roi[mouth_region_y:h, 0:w]
            
            smiles_detected = smile_cascade.detectMultiScale(
                mouth_region,
                scaleFactor=1.3,
                minNeighbors=22,  # –£–í–ï–õ–ò–ß–ï–ù–û —Å 20 –¥–æ 22 (—Å—Ç—Ä–æ–∂–µ)
                minSize=(int(w*0.25), int(h*0.15))
            )
            
            is_smiling = len(smiles_detected) > 0
            print(f'[TECH_SORT] Smile detection: {len(smiles_detected)} smiles found ‚Üí {"üòä SMILING" if is_smiling else "neutral"}')
            
            # –®–ê–ì 2: –î–µ—Ç–µ–∫—Ü–∏—è –≥–ª–∞–∑
            eye_region_y = int(h * 0.25)
            eye_region_h = int(h * 0.25)
            eye_region = face_roi[eye_region_y:eye_region_y + eye_region_h, 0:w]
            
            if eye_region.size == 0:
                faces_ok += 1  # –ù–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å - —Å—á–∏—Ç–∞–µ–º OK
                continue
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –≥–ª–∞–∑ –∫–∞—Å–∫–∞–¥–æ–º (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)
            eyes_detected = eye_cascade.detectMultiScale(
                eye_region, 
                scaleFactor=1.1,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 1.03 (–º–µ–Ω—å—à–µ –º–∞—Å—à—Ç–∞–±–æ–≤ = –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏)
                minNeighbors=3,   # –°–Ω–∏–∂–µ–Ω–æ —Å 4 (–º–µ–Ω—å—à–µ –ø—Ä–æ—Ö–æ–¥–æ–≤)
                minSize=(int(w*0.15), int(h*0.2))  # –£–≤–µ–ª–∏—á–µ–Ω –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            )
            
            print(f'[TECH_SORT] Eyes detected by cascade: {len(eyes_detected)}')
            
            # –¢—Ä–æ–π–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è (–∏—â–µ–º –∑—Ä–∞—á–∫–∏)
            _, binary_dark_strict = cv2.threshold(eye_region, 40, 255, cv2.THRESH_BINARY_INV)  # –ü–æ–Ω–∏–∂–µ–Ω —Å 45 –¥–æ 40
            
            binary_dark_adaptive = cv2.adaptiveThreshold(
                eye_region, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY_INV, 13, 3
            )
            
            _, binary_dark_otsu = cv2.threshold(eye_region, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            binary_dark = cv2.bitwise_or(binary_dark_strict, binary_dark_adaptive)
            binary_dark = cv2.bitwise_or(binary_dark, binary_dark_otsu)
            
            # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            binary_dark = cv2.morphologyEx(binary_dark, cv2.MORPH_CLOSE, kernel)
            
            # –ü–æ–∏—Å–∫ –∫—Ä—É–≥–ª—ã—Ö –∫–æ–Ω—Ç—É—Ä–æ–≤ (–∑—Ä–∞—á–∫–∏)
            contours, _ = cv2.findContours(binary_dark, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            circular_contours = 0
            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = max(12, (w * h) / 2000)  # –ü–æ–Ω–∏–∂–µ–Ω —Å 15 –∏ 1800
                max_area = (w * h) / 8
                
                if area < min_area or area > max_area:
                    continue
                
                perimeter = cv2.arcLength(contour, True)
                if perimeter == 0:
                    continue
                
                circularity = 4 * np.pi * area / (perimeter * perimeter)
                
                x_cnt, y_cnt, w_cnt, h_cnt = cv2.boundingRect(contour)
                aspect_ratio = w_cnt / float(h_cnt) if h_cnt > 0 else 0
                
                # –°–¢–†–û–ñ–ï –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫—Ä—É–≥–ª–æ—Å—Ç—å (–ø–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥)
                if circularity > 0.6 and 0.65 <= aspect_ratio <= 1.5:  # –ë—ã–ª–æ 0.65/0.7-1.4
                    circular_contours += 1
                    print(f'[TECH_SORT] Pupil candidate: area={area:.1f}, circularity={circularity:.2f}, aspect={aspect_ratio:.2f}')
            
            print(f'[TECH_SORT] Circular contours found (pupils): {circular_contours}')
            
            # –ê–Ω–∞–ª–∏–∑ —è—Ä–∫–æ—Å—Ç–∏ –æ–±–ª–∞—Å—Ç–∏ –≥–ª–∞–∑
            mean_brightness = np.mean(eye_region)
            std_brightness = np.std(eye_region)
            print(f'[TECH_SORT] Eye region: mean_brightness={mean_brightness:.1f}, std={std_brightness:.1f}')
            
            # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –°–¢–†–û–ñ–ï –∫ –∑–∞–∫—Ä—ã—Ç–∏—é –≥–ª–∞–∑ (–º–µ–Ω—å—à–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)
            # –ì–ª–∞–∑–∞ –û–î–ù–û–ó–ù–ê–ß–ù–û –û–¢–ö–†–´–¢–´ –µ—Å–ª–∏:
            # 1. –ö–∞—Å–∫–∞–¥ –Ω–∞—à—ë–ª 2+ –≥–ª–∞–∑–∞ (–¥–∞–∂–µ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —è—Ä–∫–æ—Å—Ç–∏) –ò–õ–ò
            # 2. –ù–∞–π–¥–µ–Ω–æ 2+ –∑—Ä–∞—á–∫–∞ –ò–õ–ò
            # 3. –ù–∞–π–¥–µ–Ω–æ 1+ –≥–ª–∞–∑ –∫–∞—Å–∫–∞–¥–æ–º –ò —è—Ä–∫–æ—Å—Ç—å > 50 –ò–õ–ò
            # 4. –Ø—Ä–∫–æ—Å—Ç—å > 65 (–æ—á–µ–Ω—å —Å–≤–µ—Ç–ª–∞—è –æ–±–ª–∞—Å—Ç—å - —Ç–æ—á–Ω–æ –æ—Ç–∫—Ä—ã—Ç—ã) –ò–õ–ò
            # 5. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ > 30 (–∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å - –∑—Ä–∞—á–æ–∫+–±–µ–ª–æ–∫)
            
            eyes_definitely_open = False
            
            if len(eyes_detected) >= 2:
                eyes_definitely_open = True
                print(f'[TECH_SORT] ‚úÖ Eyes DEFINITELY open: cascade found 2+ eyes')
            elif circular_contours >= 2:
                eyes_definitely_open = True
                print(f'[TECH_SORT] ‚úÖ Eyes DEFINITELY open: found 2+ circular pupils')
            elif len(eyes_detected) >= 1 and mean_brightness > 50:
                eyes_definitely_open = True
                print(f'[TECH_SORT] ‚úÖ Eyes DEFINITELY open: 1 eye detected + brightness > 50')
            elif mean_brightness > 65:
                eyes_definitely_open = True
                print(f'[TECH_SORT] ‚úÖ Eyes DEFINITELY open: very bright region (>{mean_brightness:.1f})')
            elif std_brightness > 30:
                eyes_definitely_open = True
                print(f'[TECH_SORT] ‚úÖ Eyes DEFINITELY open: high contrast (std={std_brightness:.1f} > 30)')
            elif circular_contours >= 1 and mean_brightness > 45:
                eyes_definitely_open = True
                print(f'[TECH_SORT] ‚úÖ Eyes DEFINITELY open: 1+ pupil + brightness > 45')
            else:
                print(f'[TECH_SORT] ‚ö†Ô∏è UNCERTAIN: cascade={len(eyes_detected)}, pupils={circular_contours}, brightness={mean_brightness:.1f}, std={std_brightness:.1f}')
            
            # –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
            if eyes_definitely_open:
                faces_ok += 1
                print(f'[TECH_SORT] Face verdict: ‚úÖ Eyes open ‚Üí OK')
            elif is_smiling:
                faces_ok += 1
                print(f'[TECH_SORT] Face verdict: üòä Smiling (uncertain eyes) ‚Üí OK (–Ω–µ –±—Ä–∞–∫–æ–≤–∞—Ç—å)')
            elif len(eyes_detected) == 0 and circular_contours == 0 and mean_brightness < 45:
                # –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –í–°–ï –ø—Ä–∏–∑–Ω–∞–∫–∏ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –∑–∞–∫—Ä—ã—Ç—ã–µ –≥–ª–∞–∑–∞
                faces_with_definitely_closed_eyes += 1
                print(f'[TECH_SORT] Face verdict: ‚ùå Eyes DEFINITELY closed ‚Üí REJECT')
            else:
                # –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª—É—á–∞–π - –ù–ï –±—Ä–∞–∫–æ–≤–∞—Ç—å (–ª—É—á—à–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –±—Ä–∞–∫ —á–µ–º –æ—Ç–±—Ä–∞–∫–æ–≤–∞—Ç—å –Ω–æ—Ä–º—É)
                faces_ok += 1
                print(f'[TECH_SORT] Face verdict: ‚ö†Ô∏è UNCERTAIN ‚Üí OK (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)')
        
        # –ò—Ç–æ–≥: –±—Ä–∞–∫–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å –û–î–ù–û–ó–ù–ê–ß–ù–û –∑–∞–∫—Ä—ã—Ç—ã–µ –≥–ª–∞–∑–∞ –ë–ï–ó —É–ª—ã–±–∫–∏
        is_rejected = faces_with_definitely_closed_eyes > 0
        print(f'[TECH_SORT] Final: faces_ok={faces_ok}, faces_definitely_closed={faces_with_definitely_closed_eyes} ‚Üí {"‚ùå REJECT" if is_rejected else "‚úÖ ACCEPT"}')
        return is_rejected
        
    except Exception as e:
        print(f'[TECH_SORT] Error in eye detection: {str(e)}')
        return False


def detect_blur(img: np.ndarray) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑–∫–æ—Å—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —á–µ—Ä–µ–∑ Laplacian variance"""
    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        is_blurry = laplacian_var < 100
        print(f'[TECH_SORT] Blur score: {laplacian_var:.2f} (threshold=100) ‚Üí {"‚ùå BLURRY" if is_blurry else "‚úÖ SHARP"}')
        
        return is_blurry
    except Exception as e:
        print(f'[TECH_SORT] Error in blur detection: {str(e)}')
        return False


def detect_overexposed(img: np.ndarray) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–µ—Ä–µ—Å–≤–µ—Ç (overexposure)"""
    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        bright_pixels = np.sum(gray > 240)
        total_pixels = gray.size
        bright_ratio = bright_pixels / total_pixels
        
        is_overexposed = bright_ratio > 0.3
        print(f'[TECH_SORT] Overexposure: {bright_ratio*100:.1f}% bright pixels (threshold=30%) ‚Üí {"‚ùå OVEREXPOSED" if is_overexposed else "‚úÖ OK"}')
        
        return is_overexposed
    except Exception as e:
        print(f'[TECH_SORT] Error in overexposure detection: {str(e)}')
        return False


def detect_underexposed(img: np.ndarray) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ–¥–æ—Å–≤–µ—Ç (underexposure)"""
    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        dark_pixels = np.sum(gray < 30)
        total_pixels = gray.size
        dark_ratio = dark_pixels / total_pixels
        
        is_underexposed = dark_ratio > 0.4
        print(f'[TECH_SORT] Underexposure: {dark_ratio*100:.1f}% dark pixels (threshold=40%) ‚Üí {"‚ùå UNDEREXPOSED" if is_underexposed else "‚úÖ OK"}')
        
        return is_underexposed
    except Exception as e:
        print(f'[TECH_SORT] Error in underexposure detection: {str(e)}')
        return False


def analyze_photo(s3_client, bucket: str, s3_key: str) -> Tuple[bool, str]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –±—Ä–∞–∫
    Returns: (is_rejected, reject_reason)
    """
    try:
        print(f'[TECH_SORT] Analyzing photo: {s3_key}')
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ü–ï–†–ï–î –∑–∞–≥—Ä—É–∑–∫–æ–π (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ OOM)
        head_response = s3_client.head_object(Bucket=bucket, Key=s3_key)
        file_size_mb = head_response['ContentLength'] / (1024 * 1024)
        print(f'[TECH_SORT] File size: {file_size_mb:.1f} MB')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã > 35 –ú–ë (–Ω–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –≤ Cloud Functions 256MB)
        if file_size_mb > 35:
            print(f'[TECH_SORT] ‚ö†Ô∏è File too large ({file_size_mb:.1f} MB), skipping to prevent OOM')
            return False, ''  # –ù–µ –±—Ä–∞–∫–æ–≤–∞—Ç—å, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ –∏–∑ S3
        response = s3_client.get_object(Bucket=bucket, Key=s3_key)
        img_data = response['Body'].read()
        print(f'[TECH_SORT] Downloaded {len(img_data)} bytes')
        
        # –î–ª—è RAW —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π thumbnail (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏)
        is_raw = s3_key.lower().endswith(('.cr2', '.nef', '.arw', '.raw', '.dng'))
        
        if is_raw:
            print(f'[TECH_SORT] RAW file detected ({len(img_data)} bytes), extracting thumbnail')
            try:
                import rawpy
                import gc
                
                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ —Ä–∞–±–æ—Ç–æ–π —Å RAW
                gc.collect()
                print(f'[TECH_SORT] Memory cleared, opening RAW stream')
                
                raw_stream = io.BytesIO(img_data)
                with rawpy.imread(raw_stream) as raw:
                    print(f'[TECH_SORT] RAW opened, extracting thumbnail')
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π JPEG preview –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ RAW (–≤ 10x –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏)
                    try:
                        thumb = raw.extract_thumb()
                        print(f'[TECH_SORT] Thumbnail extracted, format={thumb.format}')
                        
                        if thumb.format == rawpy.ThumbFormat.JPEG:
                            thumb_data = io.BytesIO(thumb.data)
                            pil_img = Image.open(thumb_data)
                            print(f'[TECH_SORT] JPEG thumbnail size: {pil_img.size}')
                            
                            # –ö–†–ò–¢–ò–ß–ù–û: –£–º–µ–Ω—å—à–∞–µ–º thumbnail –î–û –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ numpy (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏)
                            # –ü–æ–Ω–∏–∂–µ–Ω–æ –¥–æ 640px –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è OOM –≤ Cloud Functions (256MB RAM)
                            max_dim = 640
                            if max(pil_img.size) > max_dim:
                                scale = max_dim / max(pil_img.size)
                                new_size = (int(pil_img.size[0] * scale), int(pil_img.size[1] * scale))
                                pil_img = pil_img.resize(new_size, Image.Resampling.LANCZOS)
                                print(f'[TECH_SORT] Resized thumbnail to: {pil_img.size}')
                            
                            img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                            print(f'[TECH_SORT] ‚úÖ Used embedded JPEG thumbnail from RAW')
                            # –û—á–∏—â–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                            del thumb_data, pil_img, thumb
                            gc.collect()
                        else:
                            print(f'[TECH_SORT] No JPEG thumbnail, using half-size decode')
                            # –ï—Å–ª–∏ thumbnail –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—ã–π demosaic —Å —É–º–µ–Ω—å—à–µ–Ω–∏–µ–º
                            rgb = raw.postprocess(half_size=True, use_camera_wb=True, no_auto_bright=True)
                            img = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
                            print(f'[TECH_SORT] ‚úÖ Used half-size RAW decode')
                            del rgb
                            gc.collect()
                    except Exception as thumb_err:
                        print(f'[TECH_SORT] Thumbnail extraction failed: {str(thumb_err)}')
                        # –ü—Ä–æ–±—É–µ–º fallback –Ω–∞ half_size decode
                        print(f'[TECH_SORT] Trying half_size decode as fallback')
                        rgb = raw.postprocess(half_size=True, use_camera_wb=True, no_auto_bright=True)
                        img = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
                        print(f'[TECH_SORT] ‚úÖ Used half-size RAW decode (fallback)')
                        del rgb
                        gc.collect()
                
                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ RAW
                del raw_stream
                del img_data
                gc.collect()
                print(f'[TECH_SORT] RAW processing completed, memory cleaned')
                
            except Exception as raw_err:
                print(f'[TECH_SORT] ‚ùå RAW decode failed: {str(raw_err)}')
                import traceback
                traceback.print_exc()
                img = None
        else:
            img = None
        
        # –ï—Å–ª–∏ RAW –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª—Å—è –∏–ª–∏ —ç—Ç–æ –Ω–µ RAW - –ø—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        if img is None:
            try:
                pil_img = Image.open(io.BytesIO(img_data))
                if pil_img.mode != 'RGB':
                    pil_img = pil_img.convert('RGB')
                img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            except Exception as decode_err:
                print(f'[TECH_SORT] PIL decode failed: {str(decode_err)}, trying OpenCV')
                img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
        
        if img is None:
            print(f'[TECH_SORT] ‚ö†Ô∏è Failed to decode image')
            return False, ''
        
        original_height, original_width = img.shape[:2]
        print(f'[TECH_SORT] Image loaded: {original_width}x{original_height}')
        
        # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ 800px –ø–æ –¥–ª–∏–Ω–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ –¥–ª—è Cloud Functions 256MB)
        max_dimension = 800
        if max(original_width, original_height) > max_dimension:
            scale = max_dimension / max(original_width, original_height)
            new_width = int(original_width * scale)
            new_height = int(original_height * scale)
            img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)
            print(f'[TECH_SORT] Resized to: {new_width}x{new_height} (scale={scale:.2f})')
        
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å–ª–∏ –±—ã–ª–æ —É–º–µ–Ω—å—à–µ–Ω–∏–µ
        import gc
        gc.collect()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        
        # 1. –†–∞–∑–º—ã—Ç–∏–µ (blur)
        if detect_blur(img):
            return True, 'blur'
        
        # 2. –ü–µ—Ä–µ—Å–≤–µ—Ç (overexposure)
        if detect_overexposed(img):
            return True, 'overexposed'
        
        # 3. –ù–µ–¥–æ—Å–≤–µ—Ç (underexposure)
        if detect_underexposed(img):
            return True, 'underexposed'
        
        # 4. –ó–∞–∫—Ä—ã—Ç—ã–µ –≥–ª–∞–∑–∞ (–°–¢–†–û–ñ–ï - —Ç–æ–ª—å–∫–æ –û–î–ù–û–ó–ù–ê–ß–ù–´–ï —Å–ª—É—á–∞–∏)
        if detect_closed_eyes(img):
            return True, 'closed_eyes'
        
        # –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã - —Ñ–æ—Ç–æ –û–ö
        print(f'[TECH_SORT] ‚úÖ Photo passed all checks')
        return False, ''
        
    except Exception as e:
        print(f'[TECH_SORT] Error analyzing photo: {str(e)}')
        return False, ''


def handler(event: dict, context) -> dict:
    '''
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ –≤ –ø–∞–ø–∫–µ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –±—Ä–∞–∫ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤ tech_rejects
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
    Batch processing –ø–æ 5 —Ñ–æ—Ç–æ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –¥–ª—è RAW + –≤—ã—Å–æ–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ)
    '''
    try:
        print('[TECH_SORT] Handler started')
        print(f'[TECH_SORT] Event: {json.dumps(event, ensure_ascii=False, default=str)}')
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º OPTIONS –∑–∞–ø—Ä–æ—Å –¥–ª—è CORS
        method = event.get('httpMethod', 'POST')
        if method == 'OPTIONS':
            return {
                'statusCode': 200,
                'headers': {
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Methods': 'POST, OPTIONS',
                    'Access-Control-Allow-Headers': 'Content-Type, X-User-Id'
                },
                'body': ''
            }
        
        # –ü–∞—Ä—Å–∏–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
        body_raw = event.get('body', '{}')
        if isinstance(body_raw, str):
            try:
                body = json.loads(body_raw) if body_raw else {}
            except json.JSONDecodeError:
                body = {}
        else:
            body = body_raw if isinstance(body_raw, dict) else {}
        
        folder_id = body.get('folder_id') if isinstance(body, dict) else None
        reset_analysis = body.get('reset_analysis', False) if isinstance(body, dict) else False
        
        if not folder_id:
            return {
                'statusCode': 400,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({'error': 'folder_id is required'})
            }
        
        headers = event.get('headers', {})
        if not isinstance(headers, dict):
            headers = {}
        
        user_id = headers.get('X-User-Id') or headers.get('x-user-id')
        if not user_id:
            return {
                'statusCode': 401,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({'error': 'User not authenticated'})
            }
        
        user_id = int(user_id)
        print(f'[TECH_SORT] Processing folder_id={folder_id}, user_id={user_id}, reset_analysis={reset_analysis}')
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        dsn = os.environ.get('DATABASE_URL')
        conn = psycopg2.connect(dsn)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º S3 –∫–ª–∏–µ–Ω—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ–º Yandex Cloud S3 –∫–∞–∫ –≤ photo-restore)
        s3_client = boto3.client(
            's3',
            endpoint_url='https://storage.yandexcloud.net',
            region_name='ru-central1',
            aws_access_key_id=os.environ['YC_S3_KEY_ID'],
            aws_secret_access_key=os.environ['YC_S3_SECRET'],
            config=Config(signature_version='s3v4')
        )
        bucket = 'foto-mix'
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # –ï—Å–ª–∏ reset_analysis=True - –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –∏–∑ tech_rejects –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏
            if reset_analysis:
                print('[TECH_SORT] Resetting analysis: restoring photos from tech_rejects and clearing flags')
                
                # –ù–∞—Ö–æ–¥–∏–º –ø–∞–ø–∫—É tech_rejects
                cur.execute('''
                    SELECT id FROM t_p28211681_photo_secure_web.photo_folders
                    WHERE user_id = %s AND parent_folder_id = %s 
                      AND folder_type = 'tech_rejects' AND is_trashed = FALSE
                ''', (user_id, folder_id))
                
                tech_rejects_folder = cur.fetchone()
                
                if tech_rejects_folder:
                    tech_rejects_id = tech_rejects_folder['id']
                    print(f'[TECH_SORT] Found tech_rejects folder: {tech_rejects_id}')
                    
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Å–µ —Ñ–æ—Ç–æ –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É
                    cur.execute('''
                        UPDATE t_p28211681_photo_secure_web.photo_bank
                        SET folder_id = %s, tech_reject_reason = NULL
                        WHERE folder_id = %s AND user_id = %s AND is_trashed = FALSE
                    ''', (folder_id, tech_rejects_id, user_id))
                    
                    restored_count = cur.rowcount
                    print(f'[TECH_SORT] Restored {restored_count} photos from tech_rejects')
                    
                    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—É—é –ø–∞–ø–∫—É tech_rejects
                    cur.execute('''
                        UPDATE t_p28211681_photo_secure_web.photo_folders
                        SET is_trashed = TRUE
                        WHERE id = %s
                    ''', (tech_rejects_id,))
                    
                    print('[TECH_SORT] Deleted empty tech_rejects folder')
                
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥–∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤—Å–µ—Ö —Ñ–æ—Ç–æ –≤ –ø–∞–ø–∫–µ
                cur.execute('''
                    UPDATE t_p28211681_photo_secure_web.photo_bank
                    SET tech_analyzed = FALSE, tech_reject_reason = NULL
                    WHERE folder_id = %s AND user_id = %s AND is_trashed = FALSE
                ''', (folder_id, user_id))
                
                reset_count = cur.rowcount
                conn.commit()
                print(f'[TECH_SORT] Reset tech_analyzed flag for {reset_count} photos')
            
            # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É tech_rejects –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç (–¥–æ –≤—ã–±–æ—Ä–∫–∏ —Ñ–æ—Ç–æ, —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ –º–∞—Ä–∫–µ—Ä–æ–º)
            cur.execute('''
                SELECT id FROM t_p28211681_photo_secure_web.photo_folders
                WHERE user_id = %s AND parent_folder_id = %s 
                  AND folder_type = 'tech_rejects' AND is_trashed = FALSE
            ''', (user_id, folder_id))
            
            tech_rejects_folder = cur.fetchone()
            
            if not tech_rejects_folder:
                # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –ø–∞–ø–∫–∏
                cur.execute('''
                    SELECT folder_name FROM t_p28211681_photo_secure_web.photo_folders
                    WHERE id = %s AND user_id = %s
                ''', (folder_id, user_id))
                
                parent_folder = cur.fetchone()
                parent_name = parent_folder['folder_name'] if parent_folder else '–ó–∞–≥—Ä—É–∑–∫–∞'
                tech_rejects_name = f'{parent_name} - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –±—Ä–∞–∫'
                
                cur.execute('''
                    INSERT INTO t_p28211681_photo_secure_web.photo_folders 
                    (user_id, parent_folder_id, folder_name, folder_type, created_at)
                    VALUES (%s, %s, %s, 'tech_rejects', NOW())
                    RETURNING id
                ''', (user_id, folder_id, tech_rejects_name))
                
                tech_rejects_id = cur.fetchone()['id']
                conn.commit()
                print(f'[TECH_SORT] Created tech_rejects folder: {tech_rejects_id}')
            else:
                tech_rejects_id = tech_rejects_folder['id']
                print(f'[TECH_SORT] Using existing tech_rejects folder: {tech_rejects_id}')
            
            # –ù–∞—Ö–æ–¥–∏–º —Ñ–æ—Ç–æ –∫–æ—Ç–æ—Ä—ã–µ –µ—â—ë –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å (batch –ø–æ 5 —Ñ–æ—Ç–æ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏)
            cur.execute('''
                SELECT id, s3_key, file_name
                FROM t_p28211681_photo_secure_web.photo_bank
                WHERE folder_id = %s AND user_id = %s 
                  AND is_trashed = FALSE
                  AND (tech_analyzed = FALSE OR tech_analyzed IS NULL)
                ORDER BY created_at
                LIMIT 5
            ''', (folder_id, user_id))
            
            photos = cur.fetchall()
            print(f'[TECH_SORT] Found {len(photos)} photos to analyze')
            
            if len(photos) == 0:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                cur.execute('''
                    SELECT COUNT(*) as remaining
                    FROM t_p28211681_photo_secure_web.photo_bank
                    WHERE folder_id = %s AND user_id = %s 
                      AND is_trashed = FALSE
                      AND (tech_analyzed = FALSE OR tech_analyzed IS NULL)
                ''', (folder_id, user_id))
                
                remaining = cur.fetchone()['remaining']
                
                return {
                    'statusCode': 200,
                    'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                    'body': json.dumps({
                        'processed': 0,
                        'rejected': 0,
                        'remaining': remaining,
                        'message': 'No photos to analyze'
                    })
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ —Ñ–æ—Ç–æ
            rejected_count = 0
            processed_count = 0
            
            for photo in photos:
                photo_id = photo['id']
                s3_key = photo['s3_key']
                file_name = photo['file_name']
                
                print(f'[TECH_SORT] Processing photo {photo_id}: {file_name}')
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–æ—Ç–æ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –∫—Ä–∞—à–∞
                try:
                    is_rejected, reject_reason = analyze_photo(s3_client, bucket, s3_key)
                    
                    if is_rejected:
                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ tech_rejects
                        cur.execute('''
                            UPDATE t_p28211681_photo_secure_web.photo_bank
                            SET folder_id = %s, tech_analyzed = TRUE, tech_reject_reason = %s
                            WHERE id = %s
                        ''', (tech_rejects_id, reject_reason, photo_id))
                        
                        rejected_count += 1
                        print(f'[TECH_SORT] ‚ùå Photo {photo_id} rejected: {reject_reason}')
                    else:
                        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ
                        cur.execute('''
                            UPDATE t_p28211681_photo_secure_web.photo_bank
                            SET tech_analyzed = TRUE
                            WHERE id = %s
                        ''', (photo_id,))
                        
                        print(f'[TECH_SORT] ‚úÖ Photo {photo_id} accepted')
                    
                    processed_count += 1
                    
                except Exception as photo_err:
                    # –ï—Å–ª–∏ —Ñ–æ—Ç–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
                    print(f'[TECH_SORT] ‚ö†Ô∏è Failed to analyze photo {photo_id}: {str(photo_err)}')
                    cur.execute('''
                        UPDATE t_p28211681_photo_secure_web.photo_bank
                        SET tech_analyzed = TRUE
                        WHERE id = %s
                    ''', (photo_id,))
                    processed_count += 1
                
                # –ö–æ–º–º–∏—Ç–∏–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ñ–æ—Ç–æ + –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                conn.commit()
                import gc
                gc.collect()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –µ—â—ë –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
            cur.execute('''
                SELECT COUNT(*) as remaining
                FROM t_p28211681_photo_secure_web.photo_bank
                WHERE folder_id = %s AND user_id = %s 
                  AND is_trashed = FALSE
                  AND (tech_analyzed = FALSE OR tech_analyzed IS NULL)
            ''', (folder_id, user_id))
            
            remaining = cur.fetchone()['remaining']
            
            print(f'[TECH_SORT] Batch completed: processed={processed_count}, rejected={rejected_count}, remaining={remaining}')
            
            return {
                'statusCode': 200,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({
                    'processed': processed_count,
                    'rejected': rejected_count,
                    'remaining': remaining,
                    'tech_rejects_folder_id': tech_rejects_id
                })
            }
    
    except Exception as e:
        print(f'[TECH_SORT] Error: {str(e)}')
        import traceback
        traceback.print_exc()
        
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({'error': str(e)})
        }